# AI Studio — Event System Specification

> **Version**: 2.0
> **Status**: Draft
> **Depends on**: product-vision.md, architecture.md
> **Builds on**: future-capabilities.md (Section: "Contract: Event Bus")

---

## Why Events Are the Core

The event system is the **backbone** of AI Studio. Every feature depends on it:

| Feature | How It Uses Events |
|---|---|
| **Sessions** | Emits events for every message, tool call, LLM response |
| **Inspector** | Reads stored events to render timelines, traces, cost breakdowns |
| **Runs** | Produces events during headless execution; status tracked via events |
| **Tool Approval** | `tool.requested` → approval decision → `tool.approved` / `tool.denied` |
| **Replay** | Re-execute from a stored event sequence |
| **Cost Tracking** | `llm.response.completed` events carry token usage → aggregated for cost |

If the event system is wrong, everything breaks. If it's right, every future feature plugs in naturally.

---

## Event Envelope (v1)

Every event in the system uses this envelope. No exceptions.

```typescript
interface Event {
  /** Unique event ID (UUID v4) */
  event_id: string;

  /** Event type (dot-separated hierarchy) */
  type: string;

  /** ISO 8601 timestamp with milliseconds */
  ts: string;

  /** Session or run this event belongs to */
  session_id: string;

  /** Source system that emitted the event */
  source: string;

  /** Sequence number within the session (monotonically increasing) */
  seq: number;

  /** Event-specific data (typed per event type) */
  payload: Record<string, unknown>;
}
```

### Field Definitions

| Field | Type | Required | Description |
|---|---|---|---|
| `event_id` | UUID v4 string | Yes | Globally unique. Generated by the emitter. |
| `type` | string | Yes | Dot-separated: `category.action`. See canonical types below. |
| `ts` | string (ISO 8601) | Yes | When the event occurred. Millisecond precision: `2026-02-08T14:30:00.123Z` |
| `session_id` | UUID v4 string | Yes | Links the event to a session or run. Every event belongs to exactly one session. |
| `source` | string | Yes | Who emitted it: `sidecar.chat`, `sidecar.tools.shell`, `desktop.approval`, `ui.user` |
| `seq` | integer | Yes | Ordering within a session. Starts at 1, increments per event. The sidecar maintains this counter per session. |
| `payload` | object | Yes | Event-specific data. Can be empty `{}` but must be present. |

### Example

```json
{
  "event_id": "a1b2c3d4-e5f6-7890-abcd-ef1234567890",
  "type": "llm.response.completed",
  "ts": "2026-02-08T14:30:02.456Z",
  "session_id": "sess_abc123",
  "source": "sidecar.chat",
  "seq": 5,
  "payload": {
    "model": "claude-sonnet-4-5-20250929",
    "provider": "anthropic",
    "content": "Here's the git status output...",
    "input_tokens": 1247,
    "output_tokens": 89,
    "duration_ms": 1832,
    "stop_reason": "end_turn"
  }
}
```

---

## Canonical Event Types

Events are organized in a dot-separated hierarchy: `category.action`.

### Session Lifecycle

| Type | Emitted By | When | Key Payload Fields |
|---|---|---|---|
| `session.started` | desktop | User opens a new session | `agent_id`, `agent_name` |
| `session.resumed` | desktop | User reopens an existing session | `message_count` (prior messages loaded) |
| `session.ended` | desktop | User closes session | `total_events`, `total_duration_ms` |

### Messages

| Type | Emitted By | When | Key Payload Fields |
|---|---|---|---|
| `message.user` | desktop | User sends a message | `content` |
| `message.assistant` | sidecar | Full assistant response ready | `content`, `model`, `provider` |
| `message.system` | sidecar | System/error message | `content`, `level` |

### LLM Inference

| Type | Emitted By | When | Key Payload Fields |
|---|---|---|---|
| `llm.request.started` | sidecar | LLM API call begins | `model`, `provider`, `input_tokens` (estimated) |
| `llm.response.chunk` | sidecar | Streaming token received | `delta` (text fragment), `chunk_index` |
| `llm.response.completed` | sidecar | Full response received | `content`, `model`, `provider`, `input_tokens`, `output_tokens`, `duration_ms`, `stop_reason` |
| `llm.response.error` | sidecar | LLM call failed | `error`, `error_code`, `model`, `provider` |

### Tool Execution

| Type | Emitted By | When | Key Payload Fields |
|---|---|---|---|
| `tool.requested` | sidecar | LLM wants to use a tool | `tool_name`, `tool_input`, `mcp_server` (if MCP) |
| `tool.approved` | desktop | User or rule approved the call | `approved_by` (`user` or `rule:<rule_id>`) |
| `tool.denied` | desktop | User or rule denied the call | `denied_by`, `reason` |
| `tool.started` | sidecar | Tool execution begins | `tool_name` |
| `tool.completed` | sidecar | Tool execution finished | `tool_name`, `output`, `duration_ms`, `exit_code` (for shell) |
| `tool.error` | sidecar | Tool execution failed | `tool_name`, `error`, `duration_ms` |

### MCP

| Type | Emitted By | When | Key Payload Fields |
|---|---|---|---|
| `mcp.server.connected` | sidecar | MCP server connection established | `server_name`, `server_uri`, `tools_count` |
| `mcp.server.disconnected` | sidecar | MCP server disconnected | `server_name`, `reason` |
| `mcp.tools.discovered` | sidecar | Tools listed from MCP server | `server_name`, `tools` (list of names) |

### Run Lifecycle (For headless/batch runs)

| Type | Emitted By | When | Key Payload Fields |
|---|---|---|---|
| `run.started` | desktop | Run begins | `agent_id`, `input`, `auto_approve_rules` |
| `run.completed` | sidecar | Run finished successfully | `total_events`, `total_duration_ms`, `total_tokens` |
| `run.failed` | sidecar | Run failed | `error`, `failed_at_seq` |

---

## Event Transport

### Sidecar → Tauri: WebSocket

The sidecar exposes a WebSocket endpoint that Tauri connects to.

```
WS ws://127.0.0.1:8765/events
```

**Connection flow:**
1. Tauri connects after sidecar health check passes
2. Tauri sends auth: `{ "type": "auth", "token": "<AI_STUDIO_TOKEN>" }`
3. Sidecar validates token
4. Sidecar streams events as JSON lines (one JSON object per message)
5. If connection drops, Tauri reconnects with exponential backoff (1s, 2s, 4s, max 30s)

**Wire format (per WebSocket message):**
```json
{"event_id":"...","type":"llm.response.chunk","ts":"...","session_id":"...","source":"sidecar.chat","seq":12,"payload":{"delta":"Hello"}}
```

One event per WebSocket message. No batching on the wire (simplicity over throughput — we're on localhost).

### Tauri → UI: Tauri Events

Tauri re-emits received events to the UI using Tauri's built-in event system.

```rust
// In Tauri event bridge
window.emit("agent_event", &event)?;
```

```typescript
// In React UI
import { listen } from '@tauri-apps/api/event';

const unlisten = await listen<AgentEvent>('agent_event', (e) => {
  const event = e.payload;
  // Update Zustand store, render in Inspector, etc.
});
```

**Why not direct WebSocket from UI?**
Security. The UI runs in a WebView. If the UI connected directly to the sidecar, any XSS vulnerability could bypass tool approval. Tauri is the security boundary.

### Tauri → SQLite: Persistence

Every event received from the sidecar is written to SQLite. This is how the Inspector works — it queries stored events.

```sql
INSERT INTO events (event_id, type, ts, session_id, source, seq, payload)
VALUES (?, ?, ?, ?, ?, ?, ?);
```

**Write strategy**: Immediate write per event. For high-frequency events (`llm.response.chunk` during streaming), we batch with a 100ms flush interval to avoid excessive I/O. The batch is flushed immediately when a `llm.response.completed` event arrives.

---

## Sequence Number (`seq`) Contract

The `seq` field provides deterministic ordering within a session. This is critical for the Inspector's timeline and for replay.

**Rules:**
1. `seq` starts at 1 for each session
2. `seq` increments by 1 for each event (no gaps)
3. The sidecar maintains the counter per `session_id`
4. Desktop-originated events (`session.started`, `tool.approved`, etc.) also get `seq` numbers — Tauri assigns these from its own counter that interleaves with sidecar events
5. On replay, events are ordered by `seq`, not by `ts` (clocks can drift; sequence cannot)

**Interleaving approach:**
- Sidecar events arrive with `seq` assigned by the sidecar
- Desktop events (approval, user message) get `seq` assigned by Tauri
- Tauri maintains the master `seq` counter. When a sidecar event arrives, Tauri remaps `seq` to the master counter before storing
- This guarantees a single, gap-free sequence per session

---

## Payload Schemas (Key Event Types)

### `message.user`
```typescript
{
  content: string;           // The user's message text
}
```

### `message.assistant`
```typescript
{
  content: string;           // Full assistant response
  model: string;             // e.g., "claude-sonnet-4-5-20250929"
  provider: string;          // e.g., "anthropic"
}
```

### `llm.request.started`
```typescript
{
  model: string;
  provider: string;
  input_tokens: number;      // Estimated token count of the prompt
  message_count: number;     // Number of messages in context
}
```

### `llm.response.chunk`
```typescript
{
  delta: string;             // Text fragment
  chunk_index: number;       // 0-based index of this chunk
}
```

### `llm.response.completed`
```typescript
{
  content: string;           // Full response text
  model: string;
  provider: string;
  input_tokens: number;      // Actual (from provider API)
  output_tokens: number;     // Actual (from provider API)
  duration_ms: number;       // Wall clock time for the LLM call
  stop_reason: string;       // "end_turn", "max_tokens", "tool_use", etc.
  cost_usd?: number;         // Estimated cost (if we can calculate it)
}
```

### `tool.requested`
```typescript
{
  tool_call_id: string;      // Unique ID for this tool call (from LLM or generated)
  tool_name: string;         // e.g., "shell", "filesystem", "mcp:github:create_issue"
  tool_input: object;        // Arguments passed to the tool
  mcp_server?: string;       // MCP server name (if tool is from MCP)
}
```

### `tool.approved`
```typescript
{
  tool_call_id: string;
  approved_by: string;       // "user" or "rule:auto_approve_readonly"
}
```

### `tool.completed`
```typescript
{
  tool_call_id: string;
  tool_name: string;
  output: string | object;   // Tool output (text or structured)
  duration_ms: number;
  exit_code?: number;        // For shell commands
  artifacts?: string[];      // Paths to files created/modified
}
```

### `tool.error`
```typescript
{
  tool_call_id: string;
  tool_name: string;
  error: string;
  error_code?: string;
  duration_ms: number;
}
```

---

## Cost Calculation

The Inspector needs to show cost per turn and cumulative cost per session. Cost is calculated from `llm.response.completed` events.

### Pricing Table (Maintained in Settings)

```typescript
interface ModelPricing {
  model_pattern: string;     // Glob pattern, e.g., "claude-sonnet-*"
  input_per_1m: number;      // USD per 1M input tokens
  output_per_1m: number;     // USD per 1M output tokens
}
```

Default pricing bundled with the app (user can override in Settings):

| Model Pattern | Input $/1M | Output $/1M |
|---|---|---|
| `claude-opus-*` | 15.00 | 75.00 |
| `claude-sonnet-*` | 3.00 | 15.00 |
| `claude-haiku-*` | 0.80 | 4.00 |
| `gpt-4o*` | 2.50 | 10.00 |
| `gpt-4o-mini*` | 0.15 | 0.60 |
| `gemini-2.0-flash*` | 0.10 | 0.40 |
| `ollama:*` | 0.00 | 0.00 |

**Calculation per LLM event:**
```
cost = (input_tokens / 1_000_000 * input_per_1m) + (output_tokens / 1_000_000 * output_per_1m)
```

Cost is calculated by Tauri when persisting `llm.response.completed` events and stored alongside the event.

---

## Inspector Queries (How Events Are Consumed)

The Inspector reads from SQLite. Here are the key queries it needs:

### Get full session timeline
```sql
SELECT * FROM events
WHERE session_id = ?
ORDER BY seq ASC;
```

### Get token/cost summary for a session
```sql
SELECT
  SUM(json_extract(payload, '$.input_tokens')) as total_input_tokens,
  SUM(json_extract(payload, '$.output_tokens')) as total_output_tokens,
  SUM(json_extract(payload, '$.cost_usd')) as total_cost,
  COUNT(*) as llm_calls
FROM events
WHERE session_id = ? AND type = 'llm.response.completed';
```

### Get all tool calls for a session
```sql
SELECT * FROM events
WHERE session_id = ? AND type LIKE 'tool.%'
ORDER BY seq ASC;
```

### Get error events
```sql
SELECT * FROM events
WHERE session_id = ? AND type LIKE '%.error'
ORDER BY seq ASC;
```

### Get events after a branch point (for replay)
```sql
SELECT * FROM events
WHERE session_id = ? AND seq > ?
ORDER BY seq ASC;
```

---

## Event Lifecycle (Full Picture)

```
┌──────────────┐
│  User Action │  (types message, approves tool)
└──────┬───────┘
       │
       ▼
┌──────────────┐     invoke()      ┌──────────────────┐
│   React UI   │ ───────────────► │   Tauri (Rust)    │
└──────────────┘                   │                   │
       ▲                           │  1. Assign seq    │
       │  emit('agent_event')      │  2. Write SQLite  │
       │                           │  3. Forward to UI │
       │                           └────────┬──────────┘
       │                                    │ HTTP POST
       │                                    ▼
       │                           ┌──────────────────┐
       │                           │  Python Sidecar   │
       │                           │                   │
       │                           │  1. Call LLM      │
       │                           │  2. Execute tools  │
       │                           │  3. Emit events   │
       │                           └────────┬──────────┘
       │                                    │ WS /events
       │                           ┌────────▼──────────┐
       └───────────────────────────│   Tauri (Rust)    │
                                   │                   │
                                   │  1. Receive event │
                                   │  2. Remap seq     │
                                   │  3. Write SQLite  │
                                   │  4. Emit to UI    │
                                   └───────────────────┘
```

---

## Backward Compatibility Rules

The event system will evolve. These rules prevent breaking changes:

1. **New event types can be added freely.** Consumers must ignore unknown types.
2. **New payload fields can be added freely.** Consumers must ignore unknown fields.
3. **Existing payload fields cannot be removed or renamed.** Deprecate with a new field instead.
4. **The envelope schema is frozen at v1.** If we need to change the envelope, we create v2 and support both.
5. **`seq` ordering is sacred.** Never reorder, skip, or reuse sequence numbers.

---

## Implementation Priority

| Component | Phase | Effort | Notes |
|---|---|---|---|
| Event types definition (Python + TS) | Phase 1 | Low | Shared type definitions |
| WebSocket `/events` endpoint in sidecar | Phase 1 | Medium | FastAPI WebSocket handler |
| Event emission in chat flow | Phase 1 | Medium | Add emit calls to existing chat code |
| Tauri WebSocket client + bridge | Phase 1 | Medium | Connect to sidecar, re-emit to UI |
| SQLite event storage | Phase 1 | Medium | Write events to DB |
| Event emission in tool flow | Phase 1 | Low | Add emit calls to existing tool code |
| `llm.response.chunk` streaming | Phase 1 | Medium | Requires streaming LLM support |
| Cost calculation | Phase 2 | Low | Simple math on stored events |
| Replay from event log | Phase 2 | High | Re-execute from a point in the timeline |
| MCP events | Phase 2 | Low | Add emit calls when MCP is implemented |
